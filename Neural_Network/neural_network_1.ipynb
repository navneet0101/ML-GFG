{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Neural Network  is an interconnected group of nodes, which process data similar to the our brain network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial neural network (ANN) is inspired by the human neural network architecture. The simplest neural network consists of only one neuron and is called a perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Artificial Neural Network (ANN) is a computational model that is inspired by the way biological neural networks in the human brain process information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The basic unit of computation in a neural network is the neuron, often called a node or unit. \n",
    "\n",
    "\n",
    "- It receives input from some other nodes, or from an external source and computes an output.\n",
    "\n",
    "\n",
    "- Each input has an associated weight (w), which is assigned on the basis of its relative\n",
    "  importance to other inputs.\n",
    "\n",
    "\n",
    "- The node applies a function f  to the weighted sum of its inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer Neural Network (Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Perceptron algorithm is the simplest type of artificial neural network, it is inspired by the information processing of a single neural cell called a neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/perceptron-picture.png' width='60%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron has a input layer and a neuron. Input layer is responsible for receiving the inputs.\n",
    "\n",
    "Each input is multiplied with a weight  and the results are added together.\n",
    "\n",
    "\n",
    "The sum is then passed through an activation function.\n",
    "\n",
    "\n",
    "Activation Function(may be a non-linear function) takes the sum of weighted input (w1*x1 + w2*x2 + w3*x3 + 1*b) as an argument and return the output of the neuron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:Sigmoid or Logistic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=LogisticRegression(multi_class='multinomial',solver='saga',penalty='l1',tol=.01,verbose=True,max_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(mnist.data[:60000],mnist.target[:60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.score(mnist.data[:60000],mnist.target[:60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.score(mnist.data[60000:],mnist.target[60000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sig.PNG\" width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh or hyperbolic tangent Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tanh is also like logistic sigmoid but range of the tanh function is from (-1 to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tanh.png\" width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tan.PNG\" width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU function :Rectified linear unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most widely used activation function.\n",
    "\n",
    "\n",
    "-  It gives an output x if x is positive and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/relu.png\" width='80%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Perceptron in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris= load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.20,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale the data\n",
    "\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scd= sc.fit_transform(X_train)\n",
    "X_test_scd = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### implement perceptron\n",
    "\n",
    "#eta0:learning rate\n",
    "\n",
    "#Learning Rate: Used to limit the amount each weight is corrected each \n",
    "#time it is updated.\n",
    "    \n",
    "#n_iter:(#Epochs): The number of times to run through the training data \n",
    "#while updating the weight.\n",
    "\n",
    "ptron = Perceptron(max_iter=40,eta0=.1,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptron.fit(X_train_scd,y_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ptron.predict(X_test_scd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptron.score(X_train_scd,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multilayer perceptron (MLP) \n",
    "\n",
    "- is a feedforward artificial neural network model that maps sets of input\n",
    "  data onto a set of appropriate outputs.\n",
    "  \n",
    "  \n",
    "- consists of multiple layers \n",
    "  an input and an output layer with one or more hidden layers\n",
    "\n",
    "\n",
    "- the input layer, consists of a set of features.\n",
    "\n",
    "\n",
    "- Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation w_1x_1 + w_2x_2 + ... + w_mx_m, followed by a non-linear activation function..\n",
    "\n",
    "\n",
    "- The output layer receives the values from the last hidden layer and\n",
    "  transforms them into output values.\n",
    "\n",
    "\n",
    "- MLPs are fully connected, each node in one layer connects with a certain\n",
    "  weight to every node in the following layer.\n",
    "\n",
    "\n",
    "-  The nodes of the layers are neurons using nonlinear activation functions, except for the nodes of the input layer. \n",
    "\n",
    "\n",
    "- There can be one or more non-linear hidden layers between the input and the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mlp.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train , X_test = X[:1700],X[1700:]\n",
    "#y_train ,y_test = y[:1700],y[1700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\n",
    " #                    solver='sgd', verbose=10, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier()\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100,100),max_iter=400,\n",
    "                    solver='sgd',random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_mnist = fetch_mldata('MNIST Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000L, 784L)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the data, use the traditional train/test split\n",
    "X, y = digit_mnist.data ,digit_mnist.target\n",
    "\n",
    "\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float64))\n",
    "X_test = sc.transform(X_test.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation='relu',hidden_layer_sizes=(200,200,200),verbose=True,max_iter=40\n",
    "                    ,solver='sgd',random_state=1,tol=.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.20645138\n",
      "Iteration 2, loss = 0.43811412\n",
      "Iteration 3, loss = 0.31375611\n",
      "Iteration 4, loss = 0.26071246\n",
      "Iteration 5, loss = 0.22808474\n",
      "Iteration 6, loss = 0.20491493\n",
      "Iteration 7, loss = 0.18753617\n",
      "Iteration 8, loss = 0.17326102\n",
      "Iteration 9, loss = 0.16128231\n",
      "Iteration 10, loss = 0.15100584\n",
      "Iteration 11, loss = 0.14203108\n",
      "Iteration 12, loss = 0.13428984\n",
      "Iteration 13, loss = 0.12701207\n",
      "Iteration 14, loss = 0.12070978\n",
      "Iteration 15, loss = 0.11477579\n",
      "Iteration 16, loss = 0.10937696\n",
      "Iteration 17, loss = 0.10443184\n",
      "Iteration 18, loss = 0.09971590\n",
      "Iteration 19, loss = 0.09551222\n",
      "Iteration 20, loss = 0.09121992\n",
      "Iteration 21, loss = 0.08746825\n",
      "Iteration 22, loss = 0.08407514\n",
      "Iteration 23, loss = 0.08061840\n",
      "Iteration 24, loss = 0.07753514\n",
      "Iteration 25, loss = 0.07456655\n",
      "Iteration 26, loss = 0.07159280\n",
      "Iteration 27, loss = 0.06898285\n",
      "Iteration 28, loss = 0.06632191\n",
      "Iteration 29, loss = 0.06387395\n",
      "Iteration 30, loss = 0.06158824\n",
      "Iteration 31, loss = 0.05938274\n",
      "Iteration 32, loss = 0.05716125\n",
      "Iteration 33, loss = 0.05526857\n",
      "Iteration 34, loss = 0.05321606\n",
      "Iteration 35, loss = 0.05131998\n",
      "Iteration 36, loss = 0.04964455\n",
      "Iteration 37, loss = 0.04791387\n",
      "Iteration 38, loss = 0.04625817\n",
      "Iteration 39, loss = 0.04474302\n",
      "Iteration 40, loss = 0.04323599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 200, 200), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=40, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.001, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.961517\n",
      "Test set score: 0.950200\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.990000\n",
      "Test set score: 0.968100\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
